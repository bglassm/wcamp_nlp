import logging
from pathlib import Path
from typing import Tuple, Optional

import numpy as np
import pandas as pd
import config

from sklearn.metrics import silhouette_score

try:
    import hdbscan
except ImportError as e:
    raise ImportError(
        "ğŸ›‘ `hdbscan`ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ``pip install hdbscan``ë¡œ ì„¤ì¹˜ í›„ ì‚¬ìš©í•˜ì„¸ìš”."
    ) from e

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def cluster_embeddings(
    embeddings_2d: np.ndarray,
    min_cluster_size: int = config.HDBSCAN_MIN_CLUSTER_SIZE,
    min_samples: Optional[int] = None,
    metric: str = config.HDBSCAN_METRIC,
    cluster_selection_epsilon: float = config.HDBSCAN_SELECTION_EPS,
) -> Tuple[np.ndarray, hdbscan.HDBSCAN]:
    """
    Cluster reduced embeddings using HDBSCAN with parameters from config by default.
    - config.HANDLE_OUTLIERS=True ì´ë©´, noise(-1) ë ˆì´ë¸”ì„ config.OUTLIER_LABELë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
    """
    if embeddings_2d.ndim != 2:
        raise ValueError("`embeddings_2d` must be 2-D array (n_samples Ã— n_dim).")

    if min_samples is None:
        min_samples = (
            config.HDBSCAN_MIN_SAMPLES
            if hasattr(config, "HDBSCAN_MIN_SAMPLES")
            else max(2, min_cluster_size // 2)
        )

    logger.info(
        "ğŸ§© HDBSCAN clustering: %s â€¢ min_cluster_size=%d â€¢ min_samples=%d â€¢ metric=%s â€¢ epsilon=%.3f",
        embeddings_2d.shape,
        min_cluster_size,
        min_samples,
        metric,
        cluster_selection_epsilon,
    )

    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=min_cluster_size,
        min_samples=min_samples,
        metric=metric,
        cluster_selection_epsilon=cluster_selection_epsilon,
        prediction_data=False,
    ).fit(embeddings_2d)

    labels = clusterer.labels_
    # â”€â”€â”€â”€â”€â”€â”€ outlier ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€
    if getattr(config, "HANDLE_OUTLIERS", False):
        # labels ë°°ì—´ì˜ dtypeì„ objectë¡œ ë°”ê¿”ì•¼ ë¬¸ìì—´ê³¼ ìˆ«ìë¥¼ ì„ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        labels = np.array(
            [t if t != -1 else config.OUTLIER_LABEL for t in labels],
            dtype=object,
        )
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    n_noise = int((labels == config.OUTLIER_LABEL).sum()) if config.HANDLE_OUTLIERS else int((clusterer.labels_ == -1).sum())

    logger.info(
        "âœ… Clustering complete â€” %d clusters â€¢ %d noise/%s points",
        n_clusters,
        n_noise,
        config.OUTLIER_LABEL if config.HANDLE_OUTLIERS else "-1",
    )
    return labels, clusterer

# pipeline/clusterer.py ì•ˆì˜ evaluate_clustersë¥¼ ë‹¤ìŒìœ¼ë¡œ êµì²´

def evaluate_clusters(
    labels: np.ndarray,
    embeddings_2d: np.ndarray,
    raw_embeddings: np.ndarray | None = None,
    logger: logging.Logger | None = None,
    output_dir: Path | None = None,
    timestamp: str | None = None,
) -> None:
    """
    í´ëŸ¬ìŠ¤í„° ë¶„í¬ì™€ ì‹¤ë£¨ì—£ ì ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ê¸°ë¡/ì €ì¥í•©ë‹ˆë‹¤.
    - ë¼ë²¨ì— intì™€ str('other')ê°€ ì„ì—¬ ìˆì–´ë„ ë™ì‘
    - ì‹¤ë£¨ì—£ ê³„ì‚°ì€ ìœ íš¨ ë¼ë²¨ì´ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ìˆ˜í–‰
    - ë¶„í¬/í†µê³„ CSV ì €ì¥
    """
    lg = logger or logging.getLogger(__name__)

    # --- 1) ë¶„í¬: í˜¼í•©í˜• ë¼ë²¨ ì•ˆì „ ì²˜ë¦¬ (ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì§‘ê³„) ---
    labels_str = np.array([str(x) for x in np.asarray(labels, dtype=object)])
    uniq, counts = np.unique(labels_str, return_counts=True)
    dist_info = ", ".join(f"{c}@{u}" for u, c in zip(uniq, counts))
    lg.info("ğŸ”¢ Cluster distribution: %s", dist_info)

    if output_dir and timestamp:
        try:
            df_dist = pd.DataFrame({"cluster_label": uniq, "count": counts})
            dist_path = Path(output_dir) / f"cluster_distribution_{timestamp}.csv"
            df_dist.to_csv(dist_path, index=False, encoding="utf-8-sig")
            lg.info("ğŸ’¾ Cluster distribution saved â†’ %s", dist_path)
        except Exception:
            lg.exception("âš ï¸ failed to save cluster_distribution CSV")

    # --- 2) ì‹¤ë£¨ì—£: noise/other ì œì™¸ í›„ ìœ íš¨ì„± ì ê²€ ---
    # ì œì™¸ ëŒ€ìƒ ë¼ë²¨ ì§‘í•©: -1, 'other' (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    exclude = {"-1", "other"}
    mask = np.array([s.lower() not in exclude for s in labels_str], dtype=bool)

    # ìœ íš¨ í‘œë³¸ ìˆ˜ì™€ ìœ íš¨ ë¼ë²¨ ê°œìˆ˜ ì ê²€
    valid_n = int(mask.sum())
    valid_labels = np.unique(labels_str[mask]) if valid_n > 0 else np.array([])
    n_valid_labels = len(valid_labels)

    if valid_n >= 2 and n_valid_labels >= 2:
        from sklearn.metrics import silhouette_score

        try:
            sil_umap = float(silhouette_score(embeddings_2d[mask], labels_str[mask], metric="euclidean"))
        except Exception:
            lg.exception("âš ï¸ Silhouette (UMAP) failed")
            sil_umap = None

        sil_raw = None
        if raw_embeddings is not None:
            try:
                sil_raw = float(silhouette_score(raw_embeddings[mask], labels_str[mask], metric="cosine"))
            except Exception:
                lg.exception("âš ï¸ Silhouette (raw) failed")

        msg = "ğŸ” Silhouette"
        if sil_umap is not None:
            msg += f" (UMAP): {sil_umap:.3f}"
        if sil_raw is not None:
            msg += f" | (raw): {sil_raw:.3f}"
        lg.info(msg)

        if output_dir and timestamp:
            try:
                df_stats = pd.DataFrame([{
                    "silhouette_umap": sil_umap,
                    "silhouette_raw": sil_raw,
                    "n_clusters": int(n_valid_labels),
                    "n_noise_or_other": int((~mask).sum()),
                    "n_samples_used": valid_n,
                }])
                stats_path = Path(output_dir) / f"cluster_stats_{timestamp}.csv"
                df_stats.to_csv(stats_path, index=False, encoding="utf-8-sig")
                lg.info("ğŸ’¾ Cluster stats saved â†’ %s", stats_path)
            except Exception:
                lg.exception("âš ï¸ failed to save cluster_stats CSV")
    else:
        # ìœ íš¨ ë¼ë²¨ì´ 1ê°œê±°ë‚˜ í‘œë³¸ì´ ë¶€ì¡±í•  ë•Œ
        if valid_n < 2:
            lg.info("ğŸ” Silhouette: insufficient non-noise points (<2)")
        else:
            lg.info("ğŸ” Silhouette: only one valid label (need â‰¥2 distinct labels)")

